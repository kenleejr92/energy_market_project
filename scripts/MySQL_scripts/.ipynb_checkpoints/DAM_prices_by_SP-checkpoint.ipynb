{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import MySQLdb\n",
    "from MySQLdb.constants import FIELD_TYPE\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import holidays\n",
    "import random\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from Query_ERCOT_DB import Query_ERCOT_DB\n",
    "\n",
    "MONTHS_PER_YEAR = 12\n",
    "DAYS_PER_MONTH = 30\n",
    "HRS_PER_DAY = 24\n",
    "\n",
    "# Acquire DAM SPP for all settlement points for a specific date range\n",
    "class Query_DAM_by_SP(Query_ERCOT_DB):\n",
    "    # list of settlement points is common across all instances of the DAM_by_SP class\n",
    "    settlement_points = []\n",
    "\n",
    "    '''\n",
    "    Query the list of settlement points and remove the heading \"Settlement Point\"\n",
    "    self.start_date - start date of query\n",
    "    self.end_date - end date of query\n",
    "    self.dts - list of date_time objects in the query result\n",
    "    self.df - pandas data frame representing the query result\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        Query_ERCOT_DB.c.execute(\"\"\"SELECT DISTINCT settlement_point FROM DAM_prices_by_SPP\"\"\")\n",
    "        r = list(Query_ERCOT_DB.c.fetchall())\n",
    "        for settlement_point in r:\n",
    "            if settlement_point[0] == \"\\\"Settlement Point\\\"\":\n",
    "                continue\n",
    "            self.settlement_points.append(settlement_point[0])\n",
    "        self.start_date = None\n",
    "        self.end_date = None\n",
    "        self.dts = None\n",
    "        self.df = None\n",
    "    \n",
    "    '''\n",
    "    Query for all prices for all load zones and hubs for specified date range\n",
    "    Creates a pandas data frame of the query\n",
    "    '''\n",
    "    def query(self, sd, ed):\n",
    "        self.start_date = sd\n",
    "        self.end_date = ed\n",
    "        result_dict = {}\n",
    "        for (idx, val) in enumerate(self.settlement_points):\n",
    "            Query_ERCOT_DB.c.execute(\"\"\"SELECT delivery_date,hour_ending,spp \n",
    "                FROM DAM_prices_by_SPP \n",
    "                WHERE settlement_point = \"%s\" \n",
    "                AND delivery_date > \"%s\" \n",
    "                AND delivery_date < \"%s\" \n",
    "                ORDER BY delivery_date,hour_ending\"\"\" % (val, sd, ed))\n",
    "            result = list(Query_ERCOT_DB.c.fetchall())\n",
    "            result_dict[val] = result\n",
    "        spp_dict = {}\n",
    "        self.dts = []\n",
    "        count = 0\n",
    "        for bus_name, result in result_dict.iteritems():\n",
    "            spps = []\n",
    "            for (date, time, spp) in result:\n",
    "                time = str(int(time.split(\":\")[0])-1)\n",
    "                dt = datetime.strptime(date + \" \" + time, \"%Y-%m-%d %H\")\n",
    "                spps.append(float(spp))\n",
    "                if count == 0:\n",
    "                    self.dts.append(dt)\n",
    "            count = count + 1\n",
    "            spp_dict[bus_name] = spps\n",
    "        string_dts = [dt.strftime(\"%Y-%m-%d %H\") for dt in self.dts]\n",
    "        self.df = pd.DataFrame(data=spp_dict, index=string_dts)\n",
    "\n",
    "    '''\n",
    "    Given a load zone or hub, creates a feature data frame for the specified model\n",
    "    Model A (Benchmark):\n",
    "        Input1: Day-Type indicator\n",
    "        Input2: Hour indicator\n",
    "        Input3: Holiday indicator\n",
    "        Input4: Hourly price of day d-1\n",
    "        Input5: Hourly price of day d-7\n",
    "    Model B (more historical price data):\n",
    "        Input 1: Day type indicator, i.e. ‘‘1” for Sunday, ‘‘2” for Monday\n",
    "        Input 2: Hour indicator, i.e. ‘‘1”, ‘‘2”, . . ., ‘‘24”.\n",
    "        Input 3: Holiday indicator, i.e. ‘‘1” for holidays and ‘‘0” for working days and weekends.\n",
    "        Input 4: Price of hour h-24.\n",
    "        Input 5: Price of hour h-25.\n",
    "        Input 6: Price of hour h-47.\n",
    "        Input 7: Price of hour h-48.\n",
    "        Input 8: Price of hour h-72.\n",
    "        Input 9: Price of hour h-96.\n",
    "        Input 10: Price of hour h-120.\n",
    "        Input 11: Price of hour h-144.\n",
    "        Input 12: Price of hour h-167.\n",
    "        Input 13: Price of hour h-168.\n",
    "    Model C (exogenous variables):\n",
    "    '''\n",
    "    def construct_feature_vector_matrix(self, lzhub, model_type):\n",
    "        dflzhub = self.df[lzhub]\n",
    "        features = []\n",
    "        if model_type == \"A\":\n",
    "            for dt, price in dflzhub.iteritems():\n",
    "                pred_hour_index = dflzhub.index.get_loc(dt)\n",
    "                if pred_hour_index - 7*24 >= 0:\n",
    "                    features.append([work_day_or_holiday(string_to_date(dt)),\n",
    "                                          string_to_date(dt).hour,\n",
    "                                          string_to_date(dt).weekday()]\n",
    "                                          + dflzhub.iloc[pred_hour_index - 2*24:pred_hour_index - 1*24].tolist()\n",
    "                                          + dflzhub.iloc[pred_hour_index - 7*24:pred_hour_index - 6*24].tolist())\n",
    "            feature_labels = ['Holiday', 'Hour', 'Day']\\\n",
    "                             + [('P(h-%s)' % str(i+1)) for i in range(24, 48)][::-1]\\\n",
    "                             + [('P(h-%s)' % str(i+1)) for i in range(144, 168)][::-1]\n",
    "            numerical_features = ['Hour']\\\n",
    "                                 + [('P(h-%s)' % str(i+1)) for i in range(24, 48)][::-1]\\\n",
    "                                 + [('P(h-%s)' % str(i+1)) for i in range(144, 168)][::-1]\n",
    "            idx_wout_1st_week = list(dflzhub.index.values)[7*24:]\n",
    "            features_df = pd.DataFrame(data=features,\n",
    "                                       index=idx_wout_1st_week,\n",
    "                                       columns=feature_labels)\n",
    "            min_max_scale(features_df, numerical_features)\n",
    "            features_df = encode_onehot(features_df, 'Day')\n",
    "            #normalize numerical values\n",
    "\n",
    "            return features_df.join(dflzhub, how='left')\n",
    "    \n",
    "   \n",
    "    '''\n",
    "    Plots the prices for all load zones and hubs for the specified date range\n",
    "    '''\n",
    "    def plot(self):\n",
    "        self.df.plot()\n",
    "        plt.title(\"SPP by LZ and HUB for %s\" % self.start_date.split(\"-\")[0])\n",
    "        plt.xlabel(\"Date-Time\")\n",
    "        plt.ylabel(\"SPP\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def get_settlement_points(self):\n",
    "        return self.settlement_points\n",
    "\n",
    "'''\n",
    "Splits the feature data frame into train, test, and validation sets\n",
    "Performs seasonal sampling; splits the date range into months and then samples within each month without replacement\n",
    "    60% of each month for training\n",
    "    20% of each month for validation\n",
    "    20% of each month for testing\n",
    "'''\n",
    "def train_test_validate(ft, train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    feature_target = ft.as_matrix()\n",
    "    num_features = feature_target.shape[1]\n",
    "    \n",
    "    train_indices = []\n",
    "    for i in range(MONTHS_PER_YEAR):\n",
    "        train_i, test_i, val_i = sample_month(i, train_size, val_size, test_size)\n",
    "        train_indices = train_indices + train_i\n",
    "        test_indices =  test_indices + test_i\n",
    "        val_indices = val_indices + val_i\n",
    "\n",
    "def string_to_date(string_date):\n",
    "    return datetime.strptime(string_date, \"%Y-%m-%d %H\")\n",
    "\n",
    "def date_to_string(date):\n",
    "    return date.strftime(\"%Y-%m-%d %H\")\n",
    "\n",
    "def weekday_of_date(date):\n",
    "    return calendar.day_name[date.weekday()]\n",
    "\n",
    "def work_day_or_holiday(date):\n",
    "    us_holidays = holidays.UnitedStates()\n",
    "    if date in us_holidays or weekday_of_date(date) == \"Sunday\" or weekday_of_date(date) == \"Saturday\":\n",
    "        return int(1)\n",
    "    else: return int(0)\n",
    "    \n",
    "def encode_onehot(df, cols):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    index = df[cols].index\n",
    "    data = enc.fit_transform(df[cols].reshape(-1, 1)).toarray()\n",
    "    one_hot_df = pd.DataFrame(data=data, index=index, columns=[cols + '%s' % i for i in range(data.shape[1])])\n",
    "    del df[cols]\n",
    "    return df.join(one_hot_df, how='inner')\n",
    "\n",
    "def min_max_scale(df,cols):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df[cols] = min_max_scaler.fit_transform(df[cols])\n",
    "\n",
    "def sample_month(month_index, train_size,test_size,val_size):\n",
    "    np.random.seed(22943)\n",
    "    indices = np.arange(0, DAYS_PER_MONTH)\n",
    "    set_indices = set(indices)\n",
    "    train_indices = np.random.choice(indices,\n",
    "                                  int(DAYS_PER_MONTH*train_size),\n",
    "                                  replace=False).tolist()\n",
    "    test_indices = np.random.choice(list(set_indices.difference(set(train_indices))),\n",
    "                                 int(DAYS_PER_MONTH*test_size),\n",
    "                                 replace=False).tolist()\n",
    "    val_indices = list(set_indices.difference(set(train_indices)).difference(test_indices))\n",
    "    \n",
    "    train_indices = [i + month_index*DAYS_PER_MONTH for i in train_indices]\n",
    "    test_indices = [i + month_index*DAYS_PER_MONTH for i in test_indices]\n",
    "    val_indices = [i + month_index*DAYS_PER_MONTH for i in val_indices]\n",
    "    return train_indices, test_indices, val_indices\n",
    "\n",
    "def test_Query_DAM_by_SP():\n",
    "    qdsp = Query_DAM_by_SP()\n",
    "    qdsp.query(\"2012-01-01\", \"2012-12-31\")\n",
    "    qdsp.plot()\n",
    "    train_test_validate(qdsp.construct_feature_vector_matrix(\"HB_BUSAVG\",\"A\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qdsp = Query_DAM_by_SP()\n",
    "qdsp.query(\"2012-01-01\", \"2012-12-31\")\n",
    "features = qdsp.construct_feature_vector_matrix(\"HB_BUSAVG\",\"A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_target = features.as_matrix()\n",
    "num_features = feature_target.shape[1]\n",
    "np.random.seed(22943)\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "val_indices = []\n",
    "for i in range(MONTHS_PER_YEAR):\n",
    "    train_i, test_i, val_i = sample_month(i, 0.6, 0.2, 0.2)\n",
    "    train_indices = train_indices + train_i\n",
    "    test_indices =  test_indices + test_i\n",
    "    val_indices = val_indices + val_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[336,\n",
       " 312,\n",
       " 168,\n",
       " 192,\n",
       " 432,\n",
       " 264,\n",
       " 456,\n",
       " 72,\n",
       " 240,\n",
       " 96,\n",
       " 648,\n",
       " 552,\n",
       " 504,\n",
       " 288,\n",
       " 24,\n",
       " 576,\n",
       " 216,\n",
       " 48,\n",
       " 1056,\n",
       " 1032,\n",
       " 888,\n",
       " 912,\n",
       " 1152,\n",
       " 984,\n",
       " 1176,\n",
       " 792,\n",
       " 960,\n",
       " 816,\n",
       " 1368,\n",
       " 1272,\n",
       " 1224,\n",
       " 1008,\n",
       " 744,\n",
       " 1296,\n",
       " 936,\n",
       " 768,\n",
       " 1776,\n",
       " 1752,\n",
       " 1608,\n",
       " 1632,\n",
       " 1872,\n",
       " 1704,\n",
       " 1896,\n",
       " 1512,\n",
       " 1680,\n",
       " 1536,\n",
       " 2088,\n",
       " 1992,\n",
       " 1944,\n",
       " 1728,\n",
       " 1464,\n",
       " 2016,\n",
       " 1656,\n",
       " 1488,\n",
       " 2496,\n",
       " 2472,\n",
       " 2328,\n",
       " 2352,\n",
       " 2592,\n",
       " 2424,\n",
       " 2616,\n",
       " 2232,\n",
       " 2400,\n",
       " 2256,\n",
       " 2808,\n",
       " 2712,\n",
       " 2664,\n",
       " 2448,\n",
       " 2184,\n",
       " 2736,\n",
       " 2376,\n",
       " 2208,\n",
       " 3216,\n",
       " 3192,\n",
       " 3048,\n",
       " 3072,\n",
       " 3312,\n",
       " 3144,\n",
       " 3336,\n",
       " 2952,\n",
       " 3120,\n",
       " 2976,\n",
       " 3528,\n",
       " 3432,\n",
       " 3384,\n",
       " 3168,\n",
       " 2904,\n",
       " 3456,\n",
       " 3096,\n",
       " 2928,\n",
       " 3936,\n",
       " 3912,\n",
       " 3768,\n",
       " 3792,\n",
       " 4032,\n",
       " 3864,\n",
       " 4056,\n",
       " 3672,\n",
       " 3840,\n",
       " 3696,\n",
       " 4248,\n",
       " 4152,\n",
       " 4104,\n",
       " 3888,\n",
       " 3624,\n",
       " 4176,\n",
       " 3816,\n",
       " 3648,\n",
       " 4656,\n",
       " 4632,\n",
       " 4488,\n",
       " 4512,\n",
       " 4752,\n",
       " 4584,\n",
       " 4776,\n",
       " 4392,\n",
       " 4560,\n",
       " 4416,\n",
       " 4968,\n",
       " 4872,\n",
       " 4824,\n",
       " 4608,\n",
       " 4344,\n",
       " 4896,\n",
       " 4536,\n",
       " 4368,\n",
       " 5376,\n",
       " 5352,\n",
       " 5208,\n",
       " 5232,\n",
       " 5472,\n",
       " 5304,\n",
       " 5496,\n",
       " 5112,\n",
       " 5280,\n",
       " 5136,\n",
       " 5688,\n",
       " 5592,\n",
       " 5544,\n",
       " 5328,\n",
       " 5064,\n",
       " 5616,\n",
       " 5256,\n",
       " 5088,\n",
       " 6096,\n",
       " 6072,\n",
       " 5928,\n",
       " 5952,\n",
       " 6192,\n",
       " 6024,\n",
       " 6216,\n",
       " 5832,\n",
       " 6000,\n",
       " 5856,\n",
       " 6408,\n",
       " 6312,\n",
       " 6264,\n",
       " 6048,\n",
       " 5784,\n",
       " 6336,\n",
       " 5976,\n",
       " 5808,\n",
       " 6816,\n",
       " 6792,\n",
       " 6648,\n",
       " 6672,\n",
       " 6912,\n",
       " 6744,\n",
       " 6936,\n",
       " 6552,\n",
       " 6720,\n",
       " 6576,\n",
       " 7128,\n",
       " 7032,\n",
       " 6984,\n",
       " 6768,\n",
       " 6504,\n",
       " 7056,\n",
       " 6696,\n",
       " 6528,\n",
       " 7536,\n",
       " 7512,\n",
       " 7368,\n",
       " 7392,\n",
       " 7632,\n",
       " 7464,\n",
       " 7656,\n",
       " 7272,\n",
       " 7440,\n",
       " 7296,\n",
       " 7848,\n",
       " 7752,\n",
       " 7704,\n",
       " 7488,\n",
       " 7224,\n",
       " 7776,\n",
       " 7416,\n",
       " 7248,\n",
       " 8256,\n",
       " 8232,\n",
       " 8088,\n",
       " 8112,\n",
       " 8352,\n",
       " 8184,\n",
       " 8376,\n",
       " 7992,\n",
       " 8160,\n",
       " 8016,\n",
       " 8568,\n",
       " 8472,\n",
       " 8424,\n",
       " 8208,\n",
       " 7944,\n",
       " 8496,\n",
       " 8136,\n",
       " 7968]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices = [i*HRS_PER_DAY for i in train_indices]\n",
    "test_indices = [i*HRS_PER_DAY for i in test_indices]\n",
    "val_indices = [i*HRS_PER_DAY for i in val_indices]\n",
    "train_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_set = np.zeros((1,num_features))\n",
    "test_set = np.zeros((1,num_features))\n",
    "val_set = np.zeros((1,num_features))\n",
    "for i in train_indices:\n",
    "    train_set = np.concatenate((train_set,feature_target[i:i+HRS_PER_DAY,:]),axis=0)\n",
    "for i in test_indices:\n",
    "    test_set = np.concatenate((test_set,feature_target[i:i+HRS_PER_DAY,:]),axis=0)\n",
    "for i in test_indices:\n",
    "    val_set = np.concatenate((val_set,feature_target[i:i+HRS_PER_DAY,:]),axis=0)\n",
    "train_set = (train_set[1:, 0:num_features-1], train_set[1:, num_features-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
