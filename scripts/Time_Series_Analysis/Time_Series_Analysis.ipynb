{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MySQLdb\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/Users/kenleejr92/energy_market_project/scripts/MySQL_scripts')\n",
    "sys.path.append('/Users/kenleejr92/bin/spark-2.0.1-bin-hadoop2.7/python')\n",
    "from Query_ERCOT_DB import Query_ERCOT_DB\n",
    "import cPickle as pickle\n",
    "from datetime import datetime\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.linalg import Matrix, Matrices\n",
    "\n",
    "\n",
    "class LMP_Query(Query_ERCOT_DB):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.node_dict = {}\n",
    "        self.table_list = []\n",
    "        self.df = None\n",
    "        self.table_boundaries = {'table0':('0001', 'BLUEMD1_8X'),\n",
    "                                 'table1':('BLUEMD1_8Z', 'CHT_M'),\n",
    "                                 'table2':('CHT_X', 'DUKE_8405'),\n",
    "                                 'table3':('DUKE_8505', 'ELEVEE_E8'),\n",
    "                                 'table4':('ELEVEE_W8', 'GREENLK_L_A'),\n",
    "                                 'table5':('GREENLK_L_B', 'KEETER'),\n",
    "                                 'table6':('KEITH', 'L_CEDAHI8_1Y'),\n",
    "                                 'table7':('L_CEDAHI8_1Z', 'MOSES_1G'),\n",
    "                                 'table8':('MOSES_2G', 'PHR_8135'),\n",
    "                                 'table9':('PHR_8140', 'SANDOW1_8Y'),\n",
    "                                 'table10':('SANDOW_4G', 'TCN7225_BUS'),\n",
    "                                 'table11': ('TCN7230_BUS', 'VENSW_1777'),\n",
    "                                 'table12':('VENSW_1785', '_WC_V_C')\n",
    "                                 }\n",
    "        for i in range(0,13):\n",
    "            Query_ERCOT_DB.c.execute(\"\"\"SHOW columns FROM DAM_LMP%s\"\"\" % i)\n",
    "            result = [r[0] for r in Query_ERCOT_DB.c.fetchall()[2:]]\n",
    "            self.table_list.append(result)\n",
    "            for node in result:\n",
    "                self.node_dict[node] = i\n",
    "    \n",
    "    def query_single_node(self, node):\n",
    "        s=\"\"\"SELECT delivery_date, hour_ending, %s from DAM_LMP%s order by delivery_date, hour_ending\"\"\" % (node, self.node_dict[node])\n",
    "        Query_ERCOT_DB.c.execute(s)\n",
    "        result = list(Query_ERCOT_DB.c.fetchall())\n",
    "        fresult = []\n",
    "        for r in result:\n",
    "            temp = ()\n",
    "            date = r[0]\n",
    "            time = str(int(r[1].split(\":\")[0])-1)\n",
    "            dt = datetime.strptime(date + \" \" + time, \"%Y-%m-%d %H\")\n",
    "            for x in r[2:]:\n",
    "                if x == None: x = 0\n",
    "                temp = temp + (float(x),)\n",
    "            r = (dt,) + temp\n",
    "            fresult.append(r)\n",
    "        self.df = pd.DataFrame(data=[f[1:] for f in fresult], index=[r[0] for r in fresult], columns=[node])\n",
    "        \n",
    "    def query(self, nodes, start_date, end_date):\n",
    "        node_string=''\n",
    "        for node in nodes:\n",
    "            node_string = node_string + node + ',' + ' '\n",
    "        node_string = node_string[:-2]\n",
    "        s = \"\"\"SELECT DAM_LMP0.delivery_date, DAM_LMP0.hour_ending, %s \n",
    "                                    from DAM_LMP0 join DAM_LMP1 on (DAM_LMP0.delivery_date = DAM_LMP1.delivery_date and DAM_LMP0.hour_ending = DAM_LMP1.hour_ending) \n",
    "                                    join DAM_LMP2 on (DAM_LMP0.delivery_date = DAM_LMP2.delivery_date and DAM_LMP0.hour_ending = DAM_LMP2.hour_ending)\n",
    "                                    join DAM_LMP3 on (DAM_LMP0.delivery_date = DAM_LMP3.delivery_date and DAM_LMP0.hour_ending = DAM_LMP3.hour_ending)\n",
    "                                    join DAM_LMP4 on (DAM_LMP0.delivery_date = DAM_LMP4.delivery_date and DAM_LMP0.hour_ending = DAM_LMP4.hour_ending)\n",
    "                                    join DAM_LMP5 on (DAM_LMP0.delivery_date = DAM_LMP5.delivery_date and DAM_LMP0.hour_ending = DAM_LMP5.hour_ending)\n",
    "                                    join DAM_LMP6 on (DAM_LMP0.delivery_date = DAM_LMP6.delivery_date and DAM_LMP0.hour_ending = DAM_LMP6.hour_ending)\n",
    "                                    join DAM_LMP7 on (DAM_LMP0.delivery_date = DAM_LMP7.delivery_date and DAM_LMP0.hour_ending = DAM_LMP7.hour_ending)\n",
    "                                    join DAM_LMP8 on (DAM_LMP0.delivery_date = DAM_LMP8.delivery_date and DAM_LMP0.hour_ending = DAM_LMP8.hour_ending)\n",
    "                                    join DAM_LMP9 on (DAM_LMP0.delivery_date = DAM_LMP9.delivery_date and DAM_LMP0.hour_ending = DAM_LMP9.hour_ending)\n",
    "                                    join DAM_LMP10 on (DAM_LMP0.delivery_date = DAM_LMP10.delivery_date and DAM_LMP0.hour_ending = DAM_LMP10.hour_ending)\n",
    "                                    join DAM_LMP11 on (DAM_LMP0.delivery_date = DAM_LMP11.delivery_date and DAM_LMP0.hour_ending = DAM_LMP11.hour_ending)\n",
    "                                    join DAM_LMP12 on (DAM_LMP0.delivery_date = DAM_LMP12.delivery_date and DAM_LMP0.hour_ending = DAM_LMP12.hour_ending)\n",
    "                                    where DAM_LMP0.delivery_date > \"%s\" and DAM_LMP0.delivery_date < \"%s\";\"\"\" % (node_string, start_date, end_date)\n",
    "        Query_ERCOT_DB.c.execute(\"\"\"SELECT DAM_LMP0.delivery_date, DAM_LMP0.hour_ending, %s \n",
    "                                    from DAM_LMP0 join DAM_LMP1 on (DAM_LMP0.delivery_date = DAM_LMP1.delivery_date and DAM_LMP0.hour_ending = DAM_LMP1.hour_ending) \n",
    "                                    join DAM_LMP2 on (DAM_LMP0.delivery_date = DAM_LMP2.delivery_date and DAM_LMP0.hour_ending = DAM_LMP2.hour_ending)\n",
    "                                    join DAM_LMP3 on (DAM_LMP0.delivery_date = DAM_LMP3.delivery_date and DAM_LMP0.hour_ending = DAM_LMP3.hour_ending)\n",
    "                                    join DAM_LMP4 on (DAM_LMP0.delivery_date = DAM_LMP4.delivery_date and DAM_LMP0.hour_ending = DAM_LMP4.hour_ending)\n",
    "                                    join DAM_LMP5 on (DAM_LMP0.delivery_date = DAM_LMP5.delivery_date and DAM_LMP0.hour_ending = DAM_LMP5.hour_ending)\n",
    "                                    join DAM_LMP6 on (DAM_LMP0.delivery_date = DAM_LMP6.delivery_date and DAM_LMP0.hour_ending = DAM_LMP6.hour_ending)\n",
    "                                    join DAM_LMP7 on (DAM_LMP0.delivery_date = DAM_LMP7.delivery_date and DAM_LMP0.hour_ending = DAM_LMP7.hour_ending)\n",
    "                                    join DAM_LMP8 on (DAM_LMP0.delivery_date = DAM_LMP8.delivery_date and DAM_LMP0.hour_ending = DAM_LMP8.hour_ending)\n",
    "                                    join DAM_LMP9 on (DAM_LMP0.delivery_date = DAM_LMP9.delivery_date and DAM_LMP0.hour_ending = DAM_LMP9.hour_ending)\n",
    "                                    join DAM_LMP10 on (DAM_LMP0.delivery_date = DAM_LMP10.delivery_date and DAM_LMP0.hour_ending = DAM_LMP10.hour_ending)\n",
    "                                    join DAM_LMP11 on (DAM_LMP0.delivery_date = DAM_LMP11.delivery_date and DAM_LMP0.hour_ending = DAM_LMP11.hour_ending)\n",
    "                                    join DAM_LMP12 on (DAM_LMP0.delivery_date = DAM_LMP12.delivery_date and DAM_LMP0.hour_ending = DAM_LMP12.hour_ending)\n",
    "                                    where DAM_LMP0.delivery_date > \"%s\" and DAM_LMP0.delivery_date < \"%s\"\n",
    "                                    order by DAM_LMP0.delivery_date, DAM_LMP0.hour_ending;\"\"\" % (node_string, start_date, end_date))\n",
    "        result = list(Query_ERCOT_DB.c.fetchall())\n",
    "        fresult = []\n",
    "        for r in result:\n",
    "            temp = ()\n",
    "            date = r[0]\n",
    "            time = str(int(r[1].split(\":\")[0])-1)\n",
    "            dt = datetime.strptime(date + \" \" + time, \"%Y-%m-%d %H\")\n",
    "            for x in r[2:]:\n",
    "                if x == None: x = 0\n",
    "                temp = temp + (float(x),)\n",
    "            r = (dt,) + temp\n",
    "            fresult.append(r)\n",
    "        self.df = pd.DataFrame(data=[f[1:] for f in fresult], index=[r[0] for r in fresult], columns=nodes)\n",
    "        \n",
    "    def get_price(self, node, date, hour_ending):\n",
    "        for i in range(0,13):\n",
    "            node = append_n(node)\n",
    "            if node in self.table_columns['table%s' % i]:\n",
    "                Query_ERCOT_DB.c.execute(\"\"\"SELECT %s FROM DAM_LMP%s WHERE delivery_date = \"%s\" AND hour_ending = \\\"%s\\\"\"\"\" % (node, i, date, hour_ending))\n",
    "                result = list(Query_ERCOT_DB.c.fetchall())[0][0]\n",
    "                return result\n",
    "        \n",
    "\n",
    "def append_n(name):\n",
    "    if name[0] in ['0','1','2','3','4','5','6','7','8','9'] or name == 'LOAD':\n",
    "        name = 'n' + name\n",
    "    return name\n",
    "\n",
    "def dist(x,y):\n",
    "    cost = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == 0 or y[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            cost = cost + np.abs(y[i] - x[i])[0]\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"LMP_spark_reduction\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Random Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_obj = LMP_Query()\n",
    "np.random.seed(1111)\n",
    "idx = np.random.choice(range(0,14))\n",
    "node = np.random.choice(query_obj.table_list[idx])\n",
    "query_obj.query_single_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.67,  26.41,  26.12, ...,  18.02,  16.21,  14.49])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = query_obj.df.as_matrix()[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoCorrelation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
